{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c9cbb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T06:43:39.003971Z",
     "iopub.status.busy": "2026-02-20T06:43:39.003512Z",
     "iopub.status.idle": "2026-02-20T06:43:39.009788Z",
     "shell.execute_reply": "2026-02-20T06:43:39.008246Z"
    },
    "papermill": {
     "duration": 0.01244,
     "end_time": "2026-02-20T06:43:39.010882",
     "exception": false,
     "start_time": "2026-02-20T06:43:38.998442",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "PROJECT_ROOT = \"C:\\\\Users\\\\Owner\\\\OneDrive - University Of Houston\\\\Desktop\\\\projects\\\\vegetation-corridor-analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85537269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T06:43:39.018455Z",
     "iopub.status.busy": "2026-02-20T06:43:39.017857Z",
     "iopub.status.idle": "2026-02-20T06:43:42.867939Z",
     "shell.execute_reply": "2026-02-20T06:43:42.866584Z"
    },
    "papermill": {
     "duration": 3.855835,
     "end_time": "2026-02-20T06:43:42.869650",
     "exception": false,
     "start_time": "2026-02-20T06:43:39.013815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9524986271279516\n",
      "TEST PATH: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\test_images\\image\\test.csv\n"
     ]
    }
   ],
   "source": [
    "#testing purpose\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "# If running from Streamlit (Papermill)\n",
    "try:\n",
    "    PROJECT_ROOT\n",
    "except NameError:\n",
    "    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "DATASET_PATH = os.path.join(PROJECT_ROOT, \"dataset\", \"train\", \"train.csv\")\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# Encode the color labels numerically\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['repeated_colour'] = label_encoder.fit_transform(dataset['repeated_colour'])\n",
    "\n",
    "# Split features and target variable\n",
    "X = dataset.drop(columns=['grid', 'repeated_colour'])\n",
    "y = dataset['repeated_colour']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training with hyperparameter tuning\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Model evaluation\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "# Get unique classes from the label encoder\n",
    "unique_classes = label_encoder.classes_\n",
    "\n",
    "# Print classification report with specified labels\n",
    "#print(classification_report(y_test, y_pred, labels=range(len(unique_classes)), target_names=unique_classes, zero_division='warn'))\n",
    "\n",
    "# Load the new dataset\n",
    "TEST_DATA_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"test_images\",\n",
    "    \"image\",\n",
    "    \"test.csv\"\n",
    ")\n",
    "\n",
    "print(\"TEST PATH:\", TEST_DATA_PATH)\n",
    "\n",
    "new_data = pd.read_csv(TEST_DATA_PATH)\n",
    "# Drop the target variable from the new dataset\n",
    "new_data_features = new_data.drop(columns=['grid', 'repeated_colour'])\n",
    "\n",
    "# Make predictions\n",
    "new_predictions = rf_classifier.predict(new_data_features)\n",
    "\n",
    "# Decode the numerical predictions back to color labels\n",
    "decoded_predictions = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "# Extract grid values\n",
    "grid_values = new_data['grid']\n",
    "\n",
    "# Create a mapping of color labels to numerical representations\n",
    "color_numerical_map = {label: i for i, label in enumerate(decoded_predictions)}\n",
    "\n",
    "\n",
    "# Combine grid values with predicted colors\n",
    "predictions_with_grid = pd.DataFrame({'grid': grid_values, 'predicted_color': decoded_predictions})\n",
    "\n",
    "# Print the predictions with corresponding grid values\n",
    "# Set display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Print the DataFrame\n",
    "#print(predictions_with_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca27eb83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T06:43:42.879392Z",
     "iopub.status.busy": "2026-02-20T06:43:42.878650Z",
     "iopub.status.idle": "2026-02-20T06:43:44.754780Z",
     "shell.execute_reply": "2026-02-20T06:43:44.753536Z"
    },
    "papermill": {
     "duration": 1.883208,
     "end_time": "2026-02-20T06:43:44.756147",
     "exception": false,
     "start_time": "2026-02-20T06:43:42.872939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN PATH: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\train\\train.csv\n",
      "Exists? True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9524986271279516\n",
      "VALIDATION PATH: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\validation\\validation.csv\n",
      "Exists? True\n",
      "Saving to: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\validation\\predictions_with_grid.csv\n"
     ]
    }
   ],
   "source": [
    "#validating purpose\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "TRAIN_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"train\",\n",
    "    \"train.csv\"\n",
    ")\n",
    "\n",
    "print(\"TRAIN PATH:\", TRAIN_PATH)\n",
    "print(\"Exists?\", os.path.exists(TRAIN_PATH))\n",
    "\n",
    "dataset = pd.read_csv(TRAIN_PATH)\n",
    "# Encode the color labels numerically\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['repeated_colour'] = label_encoder.fit_transform(dataset['repeated_colour'])\n",
    "\n",
    "# Split features and target variable\n",
    "X = dataset.drop(columns=['grid', 'repeated_colour'])\n",
    "y = dataset['repeated_colour']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training with hyperparameter tuning\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Model evaluation\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "# Get unique classes from the label encoder\n",
    "unique_classes = label_encoder.classes_\n",
    "\n",
    "# Print classification report with specified labels\n",
    "#print(classification_report(y_test, y_pred, labels=range(len(unique_classes)), target_names=unique_classes, zero_division='warn'))\n",
    "\n",
    "# Load the new dataset\n",
    "VALIDATION_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"validation\",\n",
    "    \"validation.csv\"\n",
    ")\n",
    "\n",
    "print(\"VALIDATION PATH:\", VALIDATION_PATH)\n",
    "print(\"Exists?\", os.path.exists(VALIDATION_PATH))\n",
    "\n",
    "new_data = pd.read_csv(VALIDATION_PATH)\n",
    "# Drop the target variable from the new dataset\n",
    "new_data_features = new_data.drop(columns=['grid'])\n",
    "\n",
    "# Make predictions\n",
    "new_predictions = rf_classifier.predict(new_data_features)\n",
    "\n",
    "# Decode the numerical predictions back to color labels\n",
    "decoded_predictions = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "# Extract grid values\n",
    "grid_values = new_data['grid']\n",
    "\n",
    "# Create a mapping of color labels to numerical representations\n",
    "color_numerical_map = {label: i for i, label in enumerate(decoded_predictions)}\n",
    "\n",
    "\n",
    "# Combine grid values with predicted colors\n",
    "predictions_with_grid = pd.DataFrame({'grid': grid_values, 'predicted_color': decoded_predictions})\n",
    "\n",
    "# Store predictions_with_grid DataFrame into a CSV file\n",
    "OUTPUT_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"validation\",\n",
    "    \"predictions_with_grid.csv\"\n",
    ")\n",
    "\n",
    "print(\"Saving to:\", OUTPUT_PATH)\n",
    "\n",
    "predictions_with_grid.to_csv(OUTPUT_PATH, index=False)\n",
    "# Print the predictions with corresponding grid values\n",
    "# Set display options to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Print the DataFrame\n",
    "#print(predictions_with_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3729cf60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T06:43:44.764859Z",
     "iopub.status.busy": "2026-02-20T06:43:44.764260Z",
     "iopub.status.idle": "2026-02-20T06:43:44.790431Z",
     "shell.execute_reply": "2026-02-20T06:43:44.788985Z"
    },
    "papermill": {
     "duration": 0.03273,
     "end_time": "2026-02-20T06:43:44.791426",
     "exception": false,
     "start_time": "2026-02-20T06:43:44.758696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation path: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\validation\\validation.csv\n",
      "Predictions path: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\validation\\predictions_with_grid.csv\n",
      "merged_data.csv saved at: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\validation\\merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define validation folder path\n",
    "VALIDATION_DIR = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"validation\"\n",
    ")\n",
    "\n",
    "# Build file paths\n",
    "VALIDATION_CSV_PATH = os.path.join(VALIDATION_DIR, \"validation.csv\")\n",
    "PREDICTIONS_PATH = os.path.join(VALIDATION_DIR, \"predictions_with_grid.csv\")\n",
    "MERGED_OUTPUT_PATH = os.path.join(VALIDATION_DIR, \"merged_data.csv\")\n",
    "\n",
    "print(\"Validation path:\", VALIDATION_CSV_PATH)\n",
    "print(\"Predictions path:\", PREDICTIONS_PATH)\n",
    "\n",
    "# Load CSV files\n",
    "csv_data = pd.read_csv(VALIDATION_CSV_PATH)\n",
    "predictions_with_grid = pd.read_csv(PREDICTIONS_PATH)\n",
    "\n",
    "# Merge on 'grid'\n",
    "merged_data = pd.merge(csv_data, predictions_with_grid, on='grid')\n",
    "\n",
    "# Save merged file (same folder, same name as before)\n",
    "merged_data.to_csv(MERGED_OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"merged_data.csv saved at:\", MERGED_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c57cc4d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T06:43:44.799064Z",
     "iopub.status.busy": "2026-02-20T06:43:44.798441Z",
     "iopub.status.idle": "2026-02-20T06:43:45.453000Z",
     "shell.execute_reply": "2026-02-20T06:43:45.451351Z"
    },
    "papermill": {
     "duration": 0.660752,
     "end_time": "2026-02-20T06:43:45.454220",
     "exception": false,
     "start_time": "2026-02-20T06:43:44.793468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data path: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\validation\\merged_data.csv\n",
      "Image path: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\test_images\\image\\image.jpg\n",
      "10 21\n",
      "Segmented image saved at: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\outputs\\segmented_frame.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_9064\\712060294.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  grid_coordinates = last_row[0].strip('\"')\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_9064\\712060294.py:142: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "# Load the merged CSV file\n",
    "# Build paths using PROJECT_ROOT\n",
    "\n",
    "MERGED_DATA_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"validation\",\n",
    "    \"merged_data.csv\"\n",
    ")\n",
    "\n",
    "IMAGE_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"test_images\",\n",
    "    \"image\",\n",
    "    \"image.jpg\"\n",
    ")\n",
    "\n",
    "print(\"Merged data path:\", MERGED_DATA_PATH)\n",
    "print(\"Image path:\", IMAGE_PATH)\n",
    "\n",
    "# Load files\n",
    "merged_data = pd.read_csv(MERGED_DATA_PATH)\n",
    "image = cv2.imread(IMAGE_PATH)\n",
    "\n",
    "# Get the last row of the CSV file\n",
    "last_row = merged_data.iloc[-1]\n",
    "\n",
    "# Extract the grid coordinates from the last row\n",
    "grid_coordinates = last_row[0].strip('\"')\n",
    "\n",
    "# Extract the grid row and column using a regular expression\n",
    "match = re.match(r'Grid\\((\\d+), (\\d+)\\)', grid_coordinates)\n",
    "grid_row, grid_col = map(int, match.groups())\n",
    "#print(grid_row,grid_col)\n",
    "#print(type(grid_row))\n",
    "# Calculate the image height and width based on the grid coordinates\n",
    "image_height = grid_row * 32\n",
    "image_width = grid_col * 32\n",
    "rw=grid_row+1\n",
    "cl=grid_col+1\n",
    "print(rw,cl)\n",
    "# Define the grid size and spacing\n",
    "grid_size = 32\n",
    "grid_spacing = grid_size - 1\n",
    "\n",
    "# Create a color map based on the color_ranges variable\n",
    "color_map = {\n",
    "    \"black\": (0, 0, 0),\n",
    "    \"white\": (255, 255, 255),\n",
    "    \"Red\": (255, 0, 0),\n",
    "    \"Orange\": (255, 165, 0),\n",
    "    \"Inchworm\": (143, 188, 143),\n",
    "    \"Lawn Green\": (124, 252, 0),\n",
    "    \"Bright Green\": (100, 221, 2),\n",
    "    \"Celadon\": (172, 225, 238),\n",
    "    \"Pastel Green\": (173, 255, 47),\n",
    "    \"Green\": (0, 255, 0),\n",
    "    \"Pistachio\": (179, 238, 225),\n",
    "    \"Dollar Bill\": (255, 223, 0),\n",
    "    \"Asparagus\": (154, 205, 50),\n",
    "    \"Dark Pastel Green\": (154, 255, 154),\n",
    "    \"Camouflage Green\": (100, 149, 237),\n",
    "    \"India Green\": (34, 139, 34),\n",
    "    \"Blue\": (0, 0, 255),\n",
    "    \"Indigo\": (75, 0, 130),\n",
    "    \"Purple\": (128, 0, 128),\n",
    "    \"Pink\": (255, 192, 203),\n",
    "    \"Dark Olive Green\": (85, 107, 47),\n",
    "    \"Rifle Green\": (64, 128, 128),\n",
    "    \"RAINBOW\": (255, 0, 255)\n",
    "}\n",
    "\n",
    "# Create an empty 3D array of size image_height*image_width\n",
    "image_array = np.zeros((image_height, image_width, 3), dtype=np.uint8)\n",
    "\n",
    "# Fill the 2D array with color indexes based on the predicted_color column\n",
    "for index, row in merged_data.iterrows():\n",
    "    grid_str = row['grid']\n",
    "    match = re.match(r'Grid\\((\\d+), (\\d+)\\)', grid_str)\n",
    "    if match:\n",
    "        grid_x = int(match.group(1))\n",
    "        grid_y = int(match.group(2))\n",
    "        #print(grid_x,',',grid_y)\n",
    "        if 0 <= grid_x < rw and 0 <= grid_y < cl:\n",
    "            color_name = row['predicted_color']\n",
    "            cv=color_map[color_name]\n",
    "            #print(color_name,cv)\n",
    "            image_array[grid_x*32:grid_x*32+32, grid_y*32:grid_y*32+32,:] = cv\n",
    "        else:\n",
    "            print(f\"Grid coordinates ({grid_x}, {grid_y}) are outside the bounds of the grid\")\n",
    "    else:\n",
    "        print(f\"Could not extract grid coordinates from '{grid_str}'\")\n",
    "        \n",
    "# Function to draw the grid on an image\n",
    "def draw_grid(image):\n",
    "    # Calculate the number of grid lines\n",
    "    num_horizontal_lines = image.shape[0] // grid_spacing\n",
    "    num_vertical_lines = image.shape[1] // grid_spacing\n",
    "\n",
    "    # Draw the horizontal and vertical grid lines\n",
    "    for i in range(num_horizontal_lines):\n",
    "        start_point = (0, i * grid_spacing)\n",
    "        end_point = (image.shape[1], i * grid_spacing)\n",
    "        cv2.line(image, start_point, end_point, (255, 255, 255), 1)\n",
    "\n",
    "    for i in range(num_vertical_lines):\n",
    "        start_point = (i * grid_spacing, 0)\n",
    "        end_point = (i * grid_spacing, image.shape[0])\n",
    "        cv2.line(image, start_point, end_point, (255, 255, 255), 1)\n",
    "\n",
    "        \n",
    "# Draw the grid on both images        \n",
    "draw_grid(image)\n",
    "draw_grid(image_array)\n",
    "\n",
    "# save the segemented Frame\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_DIR, \"segmented_frame.jpg\")\n",
    "\n",
    "plt.imsave(OUTPUT_PATH, image_array)\n",
    "\n",
    "print(\"Segmented image saved at:\", OUTPUT_PATH)\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"original\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image_array)\n",
    "plt.title(\"segemented_frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a92128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T06:43:45.461565Z",
     "iopub.status.busy": "2026-02-20T06:43:45.460955Z",
     "iopub.status.idle": "2026-02-20T06:43:45.698826Z",
     "shell.execute_reply": "2026-02-20T06:43:45.696970Z"
    },
    "papermill": {
     "duration": 0.243656,
     "end_time": "2026-02-20T06:43:45.700231",
     "exception": false,
     "start_time": "2026-02-20T06:43:45.456575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify path: C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\dataset\\classification\\classify.csv\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "non_vegetation       0.23      0.44      0.30        16\n",
      "    vegetation       0.90      0.77      0.83       104\n",
      "\n",
      "      accuracy                           0.72       120\n",
      "     macro avg       0.56      0.60      0.56       120\n",
      "  weighted avg       0.81      0.72      0.76       120\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  9]\n",
      " [24 80]]\n",
      "\n",
      "True Positive Rate (TPR): 0.7692307692307693\n",
      "False Positive Rate (FPR): 0.5625\n",
      "True Negative Rate (TNR): 0.4375\n",
      "False Negative Rate (FNR): 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the CSV file\n",
    "CLASSIFY_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    \"dataset\",\n",
    "    \"classification\",\n",
    "    \"classify.csv\"\n",
    ")\n",
    "\n",
    "print(\"Classify path:\", CLASSIFY_PATH)\n",
    "\n",
    "data = pd.read_csv(CLASSIFY_PATH) # Replace 'your_csv_file.csv' with the path to your CSV file\n",
    "\n",
    "# Define true labels and predicted labels\n",
    "true_labels = data['original_image']\n",
    "predicted_labels = data['segmented_output']\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate true positive (TP), false positive (FP), true negative (TN), and false negative (FN)\n",
    "TP = cm[1][1]\n",
    "FP = cm[0][1]\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "\n",
    "# Calculate true positive rate (TPR), false positive rate (FPR), true negative rate (TNR), and false negative rate (FNR)\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (FP + TN)\n",
    "FNR = FN / (TP + FN)\n",
    "\n",
    "# Print TPR, FPR, TNR, and FNR\n",
    "print(\"\\nTrue Positive Rate (TPR):\", TPR)\n",
    "print(\"False Positive Rate (FPR):\", FPR)\n",
    "print(\"True Negative Rate (TNR):\", TNR)\n",
    "print(\"False Negative Rate (FNR):\", FNR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.39147,
   "end_time": "2026-02-20T06:43:46.566087",
   "environment_variables": {},
   "exception": null,
   "input_path": "C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\notebooks\\randomforest.ipynb",
   "output_path": "C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis\\notebooks\\randomforest.ipynb",
   "parameters": {
    "PROJECT_ROOT": "C:\\Users\\Owner\\OneDrive - University Of Houston\\Desktop\\projects\\vegetation-corridor-analysis"
   },
   "start_time": "2026-02-20T06:43:36.174617",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}